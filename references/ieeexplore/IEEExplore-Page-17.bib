@ARTICLE{11063417,
  author={He, Chunhua and Huang, Wei and Huang, Yi and Wang, Haojie and Wu, Heng and Deng, Songqing and Liang, Maojin},
  journal={IEEE Internet of Things Journal}, 
  title={A Portable Neurofeedback Training System for Attention Improvement Based on High-Performance Edge CNN Accelerator}, 
  year={2025},
  volume={12},
  number={18},
  pages={38292-38306},
  abstract={Currently, many people around the world, especially children and youth, are facing the problem of attention deficit. neurofeedback training (NFT) is proved to be an effective method for improving the attention level. However, current NFT typically requires the use of computers or other nonportable devices, which limits the application scenarios of this technique. Therefore, a portable NFT system based on high-performance edge AI accelerator is proposed in this article. More specifically, the real-time single-channel electroencephalogram (EEG) and electrocardiogram (ECG) signals of the trainees are first collected by the wearable flexible headband and patch. The wavelet packet decomposition algorithm is adopted to decompose and denoise the collected signals. The processed signals are classified by a convolutional neural network model, and an AI accelerator is designed to run this model for portability. The classification results are fed back to the trainees in real-time with a serious game to achieve the closed-loop regulation of their attentions. Finally, a single-blind controlled experiment is conducted to verify the effectiveness of the proposed system. The experimental results indicate that the attention levels of subjects trained with the proposed system are significantly improved (p < 0.05), and the attention-related EEG indicator theta/beta ratio decreased by an average of 21.85%.},
  keywords={Electroencephalography;Brain modeling;Training;Electrocardiography;Neurofeedback;Real-time systems;Feature extraction;Computational modeling;Computers;Accuracy;AI accelerator;attention improving;convolutional neural network;portable neurofeedback training (NFT) system},
  doi={10.1109/JIOT.2025.3585233},
  ISSN={2327-4662},
  month={Sep.},}@ARTICLE{9927463,
  author={Gao, Shaohua and Yang, Kailun and Shi, Hao and Wang, Kaiwei and Bai, Jian},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Review on Panoramic Imaging and Its Applications in Scene Understanding}, 
  year={2022},
  volume={71},
  number={},
  pages={1-34},
  abstract={With the rapid development of high-speed communication and artificial intelligence technologies, human perception of real-world scenes is no longer limited to the use of small Field of View (FoV) and low-dimensional scene detection devices. Panoramic imaging emerges as the next generation of innovative intelligent instruments for environmental perception and measurement. However, while satisfying the need for large-FoV photographic imaging, panoramic imaging instruments are expected to have high resolution, no blind area, miniaturization, and multidimensional intelligent perception and can be combined with artificial intelligence methods toward the next generation of intelligent instruments, enabling deeper understanding and more holistic perception of 360° real-world surrounding environments. Fortunately, recent advances in freeform surfaces, thin-plate optics, and metasurfaces provide innovative approaches to address the human perception of the environment, offering promising ideas beyond conventional optical imaging. In this review, we begin by introducing the basic principles of panoramic imaging systems and then describe the architectures, features, and functions of various panoramic imaging systems. Afterward, we discuss, in detail, the broad application prospects and great design potential of freeform surfaces, thin-plate optics, and metasurfaces in panoramic imaging. We then provide a detailed analysis of how these techniques can help enhance the performance of panoramic imaging systems. We further offer a detailed analysis of applications of panoramic imaging in scene understanding for autonomous driving and robotics, spanning panoramic semantic image segmentation, panoramic depth estimation, panoramic visual localization, and so on. Finally, we cast a perspective on future potential and research directions for panoramic imaging instruments.},
  keywords={Imaging;Optical imaging;Optical sensors;High-speed optical techniques;Instruments;Optical design;Solid modeling;Computational imaging;computer vision;intelligent instrument;multidimensional perception;panoramic imaging;panoramic optical system;scene understanding;ultrawide-angle optical system},
  doi={10.1109/TIM.2022.3216675},
  ISSN={1557-9662},
  month={},}@ARTICLE{9653662,
  author={Liu, Jinxin and Nogueira, Michele and Fernandes, Johan and Kantarci, Burak},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Adversarial Machine Learning: A Multilayer Review of the State-of-the-Art and Challenges for Wireless and Mobile Systems}, 
  year={2022},
  volume={24},
  number={1},
  pages={123-159},
  abstract={Machine Learning (ML) models are susceptible to adversarial samples that appear as normal samples but have some imperceptible noise added to them with the intention of misleading a trained classifier and misclassifying the input. Adversarial Machine Learning (AML) was initially coined following upon researchers pointing out certain blind spots in image classifiers in computer vision field which were exploited by these adversarial samples to deceive the model. Although this has been investigated remarkably in computer vision, the impact of AML in wireless and mobile systems has recently attracted attention. Wireless and mobile networks have intensely benefited from the application of ML classifiers to detect network traffic anomalies and malware detection. However, ML detectors themselves can be exfiltrated/evaded by the samples carefully designed by attackers, raising security concerns for ML-based network applications. Thus, it is crucial to detect such samples to safeguard the network. This survey article presents a systematic mapping and a comprehensive literature review on AML to wireless and mobile systems from physical layer to network and application layers. The article reviews the state-of-the-art AML approaches in the generation and detection of adversarial samples. The samples can be generated by adversarial models such as Generative Adversarial Networks (GANS) and techniques such as Fast Gradient Sign Method (FGSM). The samples can be detected by adversarial models acting as classifiers or ML classifiers reinforced with knowledge on how to detect such samples. For each approach, a high-level overview is provided alongside its impact on solving the problems in wireless and mobile settings. Furthermore, this article provides detailed discussions to highlight the open issues and challenges faced by these approaches, as well as research opportunities which can be of interest to the researchers and developers in Artificial Intelligence (AI)-driven wireless and mobile networking.},
  keywords={Wireless communication;Communication system security;Malware;Feature extraction;Wireless sensor networks;Intrusion detection;Generative adversarial networks;Wireless networks;mobile networks;adversarial machine learning;artificial intelligence;intrusion detection},
  doi={10.1109/COMST.2021.3136132},
  ISSN={1553-877X},
  month={Firstquarter},}@ARTICLE{9759483,
  author={Chang, Yuanhong and Chen, Jinglong and Wu, Wenyang and Pan, Tongyang and Zhou, Zitong and He, Shuilong},
  journal={IEEE Internet of Things Journal}, 
  title={Intelligent Fault Quantitative Identification for Industrial Internet of Things (IIoT) via a Novel Deep Dual Reinforcement Learning Model Accompanied With Insufficient Samples}, 
  year={2022},
  volume={9},
  number={20},
  pages={19811-19822},
  abstract={Industrial Internet of Things (IIoT) is mainly a data-oriented network, so intelligent processing of massive data is desiderated to realize the interconnection between machines. Currently, deep-learning-based methods are widely applied for intelligent construction of the IIoT, so as to maximize the self-monitoring and self-management capabilities of various machines. However, the quantity and quality of data and the optimization of parameters greatly limit the properties of such methods. As a breakthrough of artificial intelligence (AI), deep reinforcement learning (DRL) provides inspiration and direction, which combines the advantages of deep learning and reinforcement learning to construct an end-to-end fault identification system. Therefore, a novel deep dual reinforcement learning model was proposed, which consisted of an actor model and a critic model. The dual structures avoid the over-self-optimization of the network. The action model continually learns the knowledge of identifying unknown samples by the  $\varepsilon $ - $greedy$  algorithm, while the critic model dynamically adjusts the policy to guide the action model in right training direction. The effectiveness of the proposed method was verified by three bearing data sets. The results indicate that the proposed method enables agents to independently realize precise fault quantitative identification. The establishment of an experience storage unit overcomes the problem of insufficient samples, which avoids blind trial and error of the proposed mode.},
  keywords={Reinforcement learning;Industrial Internet of Things;Fault diagnosis;Feature extraction;Training;Deep learning;Predictive models;Deep reinforcement learning (DRL);fault quantitative identification;insufficient samples;Internet of Things},
  doi={10.1109/JIOT.2022.3168317},
  ISSN={2327-4662},
  month={Oct},}@INPROCEEDINGS{10063089,
  author={Mishra, Abhishek and Purohit, Jahanvi and Nizam, Maruf and Gawre, Suresh Kumar},
  booktitle={2023 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS)}, 
  title={Recent Advancement in Autonomous Vehicle and Driver Assistance Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In past two decades, the popularity and use of autonomous vehicles and driver assistance systems has accelerated due to the advancement in artificial intelligence techniques, big data analysis, machine learning, computer vision, smart sensors and Internet of Things (IoT). Autonomous vehicles (AVs) are gaining popularity because it reduces traffic congestion along with increase in safety and fuel efficiency. The present paper focuses on the functionality of the driver-less car and Advanced Driver & Driving Assistance Systems (ADDAS). Driver assistance systems help drivers to driving safely by avoiding and minimising distractions by observing their actions. Artificial Intelligence can be incorporated when AVs drive alongside human-driven vehicles (HVs), also known as the era of Mixed Autonomy. The Markov decision process (MDP) can be used to represent the communication between the driver-less vehicles and the surroundings, where, MDP is a discrete-time imaginary command process. MDP is utilized in various fields like automation, economics, manufacturing, and automatic control. This paper provides a detailed review on recent research and developments on autonomous vehicles and ADDAS. Some onfield examples of ADDAS are Automatic Parking, Automatic Braking System (ABS), Blind Spot Monitors, Adaptive Cruise Control (ACC), etc.},
  keywords={Deep learning;Road accidents;Markov processes;Safety;Internet of Things;Autonomous vehicles;Traffic congestion;Autonomous Vehicles (AVs);Human-Driven Vehicles (HVs);Markov Decision Process (MDP);Artificial Intelligence (AI);Advance Driving & Driver Assistance Systems (ADDAS);Deep Learning (DL);Smart Transportation Robots (STR)},
  doi={10.1109/SCEECS57921.2023.10063089},
  ISSN={2688-0288},
  month={Feb},}@INPROCEEDINGS{9763591,
  author={Joisten, Karen and Thiemer, Nicole and Renner, Tobias and Janssen, Anke and Scheffler, Alexander},
  booktitle={2022 IEEE International Conference on Assured Autonomy (ICAA)}, 
  title={Focusing on the Ethical Challenges of Data Breaches and Applications}, 
  year={2022},
  volume={},
  number={},
  pages={74-82},
  abstract={Ethical challenges of the human lifeworld that are caused by data breaches and applications are steadily increasing. Therefore, a new ethical concept must be brought into focus: Technoethics for Emerging Digital Systems (TEDS). TEDS is presented as an integrative and innovative approach committed to an interdisciplinary perspective. Thereby, TEDS reflects all social areas of the human lifeworld in their ethical scope. With recourse to phenomenological methods, TEDS helps to address ethical implications which arise from deep interference of autonomous systems with the human lifeworld. The meaning of intentional structures and the problem of appresentations in the phenomenological sense still represents a blank gap in the current ethical discourse on the problem of data breaches. The findings provide methods for dealing with ethical challenges and explain the problem area of an appropriate technoethical use in the lifeworld. In this way, problems can already be avoided in the development process of artificial intelligence systems and their applications by specifically searching for blind spots in a technical and ethical manner. Furthermore, this approach helps to assure a technoethical use of autonomous systems in an appropriate way and ultimately leads to a limitation of damages – which may occur in case of malfunctions and data breaches of artificial intelligence systems – in the lifeworld of humans. Our contribution is to introduce TEDS as a new ethical concept that has not existed before. This new concept focuses on the application of phenomenological methods to detect ethical errors in digital systems.},
  keywords={Ethics;Data privacy;Autonomous systems;Digital systems;Focusing;Interference;Data breach;Technoethics;ethics;phenomenology;application;privacy;security;AI;autonomous systems;physical world/lifeworld},
  doi={10.1109/ICAA52185.2022.00018},
  ISSN={},
  month={March},}@INPROCEEDINGS{10434146,
  author={Sharon, Felicia and Sellamuthu, Suseela and S, Nachiyappan and V, Akila},
  booktitle={2023 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Framework for Face recognition and Scene Description using Deep Learning for Visually Challenged people}, 
  year={2023},
  volume={},
  number={},
  pages={1-11},
  abstract={In today's world, independent living becomes increasingly crucial for those who are visually impaired, as they encounter numerous challenges. Visually impaired people are at a disadvantage since they need manual help to compel information about their surroundings. Since many tasks require visual information, visually impaired persons find it difficult to complete many of life's essential chores, such as going for a stroll, eating, and conversing with a group of people. As technology has advanced, helping the blind is now possible. This project offers an advanced solution to assist visually challenged individuals, taking advantage of recent advancements in Artificial Intelligence (AI) Technologies and Deep Learning frameworks. This project proposes a sophisticated system to help visually challenged people. The system uses a novel strategy of combining Deep Learning Faster R-CNN ResNet-50 FPN for object detection, CNN ResNet-50 for Face recognition, and CNN ResNet-50 and LSTM for Image Captioning and adding some more objects to the existing dataset to customize it for visually impaired people. Then a voice message is generated to assist the Visually Impaired person. Furthermore, each of the models used in the system is compared with two other models to determine the most effective model. Of all the three models used for Face recognition, Image Captioning, and Object detection, the proposed system performs the best with 80.6%, 0.493(BLEU-1), and 92.7% respectively.},
  keywords={Deep learning;Visualization;Face recognition;Computational modeling;Object detection;Artificial intelligence;Task analysis;Object Detection;Image Captioning;Face Recognition;ResNet;CNN;RNN;LSTM},
  doi={10.1109/ICERCS57948.2023.10434146},
  ISSN={},
  month={Dec},}@ARTICLE{10729218,
  author={Chen, Shuting and Wei, Dezhi and Hong, Chengxi and Li, Li and Qiu, Xiuliang and Jia, Hong},
  journal={IEEE Access}, 
  title={GlauSeg-Net: Retinal Fundus Medical Image Automatic Segmentation With Multi-Task Learning for Glaucoma Early Screening}, 
  year={2024},
  volume={12},
  number={},
  pages={159982-159994},
  abstract={Glaucoma is one of the leading causes of irreversible vision loss globally, often resulting in going blind. Early detection and treatment are critical in mitigating its impact, with retinal fundus imaging being the most common method for early screening. Traditionally, glaucoma is diagnosed by examining structural changes in these images, but this process heavily relies on the subjective judgment of clinicians, which can lead to errors. With the advent of artificial intelligence (AI), computer-aided diagnostic systems have emerged as powerful tools for early glaucoma screening, offering diagnostic accuracy comparable to that of expert ophthalmologists. Accurate glaucoma diagnosis from fundus images hinges on the precise calculation of the optic cup-to-disc ratio, which depends on the accurate segmentation of the optic cup and disc. Given that these regions occupy only a small portion of the fundus image, traditional deep learning methods typically approach segmentation in two stages: first, by locating the optic cup and disc through object detection, and then by performing fine-grained segmentation within the identified regions. However, the effectiveness of these methods is often constrained by the initial detection accuracy. In this paper, we introduce a novel one-stage segmentation framework, GlauSeg-Net, specifically designed for early glaucoma screening using retinal fundus images. Our method leverages a multi-task learning strategy that employs weak labels to pre-locate the segmentation target within feature layers, significantly enhancing the performance of small target segmentation. Experimental results demonstrate that proposed GlauSeg-Net get 96.8% and 88.3% segmentation accuracy on optic disc and optic cup respectively, and outperforms mainstream benchmark methods in segmentation accuracy.},
  keywords={Optical imaging;Biomedical optical imaging;Image segmentation;Feature extraction;Retina;Glaucoma;Integrated optics;Optical fiber networks;Accuracy;Semantics;Multitasking;Cetinal fundus medical image;glaucoma;optic disc;optic cup;segmentation;multi-task learning},
  doi={10.1109/ACCESS.2024.3484430},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10672952,
  author={Li, Zhuyu and Xiong, Bing and Huang, Jialing and Xie, Zhuojiang and Guo, Tingli and Gu, Hao},
  booktitle={2024 7th International Conference on Electronics Technology (ICET)}, 
  title={An Intelligent Navigation System for the Visually Impaired Based on Machine Vision}, 
  year={2024},
  volume={},
  number={},
  pages={875-879},
  abstract={In recent years, the number of visually impaired individuals has increased, and the urbanization process and lack of portable assistive tools have increased the risks associated with their mobility. This paper introduces the traditional blind cane as a carrier and integrates Internet of Things (IoT) and artificial intelligence (AI) technologies by installing sensor modules such as Bluetooth, cameras, ultrasonic obstacle avoidance, and voice broadcasting on the cane. Based on cloud service platforms and the YOLOv5 algorithm, an intelligent navigation cane has been developed that can achieve intelligent obstacle avoidance, traffic and road condition recognition, and other functions. Furthermore, an accessible navigation app has been developed that integrates various public transportation resources and enables Bluetooth connection, one-click cane retrieval, and travel navigation. This forms a complete smart navigation system for visually impaired individuals, providing them with security, independence, and long-distance travel support.},
  keywords={YOLO;Cloud computing;Bluetooth;Navigation;Roads;Safety;Internet of Things;Blind canes;Intelligent navigation system;Machine vision;IoT},
  doi={10.1109/ICET61945.2024.10672952},
  ISSN={2768-6515},
  month={May},}@INPROCEEDINGS{11102543,
  author={Singh, Aryan and Garg, Harshul and Kumar, Gaurav and Raj, Gaurav and Agrawal, Arun Prakash},
  booktitle={2025 International Conference on Networks and Cryptology (NETCRYPT)}, 
  title={Leveraging AWS Rekognition, Translate, and Polly for Multilingual Image-to-Text Translation and Speech Synthesis}, 
  year={2025},
  volume={},
  number={},
  pages={704-710},
  abstract={Using AWS Rekognition, Translate, and Polly: Multilingual Image-to-Text Translation and Speech Synthesis Abstract Over the last decade, cloud-based artificial intelligence services have changed the way data is interacted with, providing scalable solutions to complex tasks and indeed reaching from image recognition to text translation or text-to-speech synthesis. This paper presents an innovative system that is powered by three Amazon Web Services: AWS Rekognition, AWS Translate, and AWS Polly, fully integrated within a unified pipeline that allows for extraction from image to text, multilingual translation, and also synthesis of speech from texts. The objectives of this system are as follows: extracting text from images, translating it into a language that he prefers, and finally converting the translated text into words. This will enable tremendous real-world applications, including providing information to the blind, translation of documents in multiple languages, and further enrichment in interactive customer services. This entire process is automated and optimized by bringing these AWS services together, thus reducing human intervention to a great extent. Our testing reveals that the system accurately identifies printed as well as handwritten content, does high-accuracy translation, and generates quality speech in multiple languages. This system is scalable, accurate, and real time. It finds applications across various industries. The base of this research opens pathways for using the powerful AI tools in AWS to build automated, multilingual, and accessible solutions.},
  keywords={Translation;Accuracy;Web services;Streaming media;Real-time systems;User experience;Multilingual;Text to speech;Artificial intelligence;Testing;AWS Rekognition;AWS Translate;AWS Polly;Image-to-Text;Text Translation;Text-to-Speech;Cloud Computing;AI-ML;Multilingual Systems},
  doi={10.1109/NETCRYPT65877.2025.11102543},
  ISSN={},
  month={May},}@INPROCEEDINGS{11198620,
  author={CHEN, Xiangdong and CUI, Heng and WANG, Fan and PAN, Tianshengnan and LIM, PheiChin},
  booktitle={2025 14th International Conference on Information Technology in Asia (CITA)}, 
  title={Smart Assistance for the Disabled: Design and Implementation of an Accessible Employment Service Platform Based on GPT Technology}, 
  year={2025},
  volume={},
  number={},
  pages={84-89},
  abstract={The disabled population faces issues such as limited job search channels, insufficient skill matching, and social prejudice in the job market. In response to the “14th Five-Year Plan” for the protection and development of the disabled people in China, this paper designs and implements an accessible employment service platform based on GPT technology - “Smart Assistance for the Disabled”. The platform uses artificial intelligence and big data analysis to provide personalized job recommendations and intelligent skill training, as well as multimodal interaction assistance tools. It also builds a comprehensive employment service system through policy interpretation, enterprise cooperation, and psychological support modules. Adhering to the WCAG 2.1 standard, usability tests show that the platform significantly improves job search efficiency (by 42%) and employment quality for disabled people, providing an innovative solution for high-quality employment.},
  keywords={Training;Technological innovation;Sign language;Accuracy;Employment;Big Data;People with disabilities;Artificial intelligence;Usability;Standards;Smart Assistance for the Disabled;GPT Technology;Accessible Design;Employment for the Disabled;Artificial Intelligence},
  doi={10.1109/CITA66455.2025.11198620},
  ISSN={},
  month={Aug},}@ARTICLE{10125064,
  author={Wang, Chunyang and Bai, Yuebin and Sun, Desen},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={CD-MSA: Cooperative and Deadline-Aware Scheduling for Efficient Multi-Tenancy on DNN Accelerators}, 
  year={2023},
  volume={34},
  number={7},
  pages={2091-2106},
  abstract={With DNN turning into the backbone of AI cloud services and propelling the emergence of INFerence-as-a-Service (INFaaS), DNN-specific accelerators have become the indispensable components of cloud inference systems. Due to the conservative “one-task-at-a-time” working mode and deadline blindness of those accelerators, implementing multi-tenancy that aims to improve the cost-effectiveness and meet SLA requirements is intractable. Recent studies including the temporal and spatial approaches, employ manifold scheduling mechanisms and sophisticated architecture innovations to address the challenge. However, these researches either still neglect the deadline awareness or render inevitable and expensive hardware overheads such as switches and storage. In this paper, we present Cooperative and Deadline-aware Multi-Systolic-Array scheduling (CD-MSA), a low-cost solution for the cloud inference that utilizes the real time mechanism and task-level parallelism to enable efficient multi-tenancy. Based on our preemptive multi-systolic-array accelerator architecture supporting the simultaneous task co-location, we first construct a fine-grained DNN execution model to lay the groundwork for the lightweight preemption. Second, we design a cooperative, deadline- and laxity-aware scheduler in conjunction with an efficient schedulability test method for better QoS guarantee without introducing additional hardware cost. Finally, to further promote the overall throughput, we propose dynamic task fusion, a software approach that fuses different tasks into the logically “multi-threading” tasks at runtime. We compare CD-MSA with several state-of-the-art researches across three multi-DNN workloads. The evaluation results show CD-MSA improves the latency-bounded throughput, SLA satisfaction rate and weighted system throughput by up to 62%, 63% and 27%, respectively.},
  keywords={Task analysis;Throughput;Systolic arrays;Real-time systems;Quality of service;System-on-chip;Processor scheduling;Domain-specific architectures;scheduling and task partitioning;accelerators;deep neural networks},
  doi={10.1109/TPDS.2023.3276759},
  ISSN={1558-2183},
  month={July},}@INPROCEEDINGS{10750625,
  author={G R, Manasa and Anchan, Anusha and T, Santhosh and H C, Hemashree and Pinnapati, Surekha and Shetty, Suvith Suresh},
  booktitle={2024 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)}, 
  title={Diabetic Retinopathy Detection from Retina Image Using Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={279-285},
  abstract={Diabetic Retinopathy is a severe complication of diabetes mellitus and one of the primary causes of blindness on a global scale. Early detection and timely intervention are crucial for preventing irreversible vision loss in affected individuals. This paper focuses on the development of an efficient Diabetic Retinopathy (DR) detection system utilizing machine learning techniques. Leveraging a dataset of high-resolution retina images, the system employs preprocessing methods such as image enhancement and normalization, followed by feature extraction to identify distinctive patterns within the images. Different machine learning algorithms, such as Support Vector Machine (SVM), logistic regression, random forest, and Naive Bayes (NB), undergo training and optimization to categorize the progression of Diabetic Retinopathy (DR) across its mild to severe stages. Additionally, explainable AI techniques are integrated to provide insights into the decision-making process of the models, enhancing transparency and trust in the system's predictions. Moreover, the proposed DR detection system offers a non-invasive, cost-effective, and scalable solution for early diagnosis, facilitating timely medical intervention and preventing the progression of diabetic retinopathy. The paper's integration with Gardio interface enables seamless output for new images, further enhancing its usability. This paper underscores the potential of machine learning in revolutionizing healthcare by contributing to the field of medical image analysis. It aims to improve diagnostic capabilities and, ultimately, enhance patient outcomes.},
  keywords={Support vector machines;Training;Diabetic retinopathy;Logistic regression;Feature extraction;Retina;Usability;Integrated circuit modeling;Random forests;Medical diagnostic imaging;Diabetic Retinopathy;Machine Learning;Image Processing},
  doi={10.1109/DISCOVER62353.2024.10750625},
  ISSN={},
  month={Oct},}@ARTICLE{10684157,
  author={Liu, Yong and Kang, Mengtian and Gao, Shuo and Zhang, Chi and Liu, Ying and Li, Shiming and Qi, Yue and Nathan, Arokia and Xu, Wenjun and Tang, Chenyu and Occhipinti, Edoardo and Yusufu, Mayinuer and Wang, Ningli and Bai, Weiling and Occhipinti, Luigi},
  journal={IEEE Internet of Things Journal}, 
  title={Diagnosis of Multiple Fundus Disorders Amidst a Scarcity of Medical Experts via Self-Supervised Machine Learning}, 
  year={2025},
  volume={12},
  number={1},
  pages={224-235},
  abstract={Fundus diseases are prevalent causes of visual impairment and blindness worldwide, particularly in regions with limited access to ophthalmologists for timely diagnosis. Current approaches to fundus disease diagnosis heavily rely on expert-annotated data and AI-assisted image analysis, offering advantages, such as improved accuracy and accessibility. However, the dependency on annotated data poses a significant challenge, especially in regions with limited resources. To address this challenge, we propose a label-free general framework based on self-supervised machine learning. We performed feature distillation on a large number of unlabeled fundus images and employed a linear classifier for the detection of different fundus diseases. In validation experiments on the public and external validation fundus data sets, our model surpassed existing supervised approaches, achieving a remarkable increase in the area under the curve (AUC) of 15.7%, and even outperformed individual human experts. Our approach offers a promising solution to the limitations of current diagnostic methods, enhancing the potential for early and accurate detection of fundus diseases in resource-constrained settings.},
  keywords={Diseases;Retina;Hospitals;Medical diagnostic imaging;Glaucoma;Training;Pathology;Diagnosis of fundus disorders;healthcare;machine learning;self-supervised learning},
  doi={10.1109/JIOT.2024.3463185},
  ISSN={2327-4662},
  month={Jan},}@INPROCEEDINGS{10581336,
  author={Fulkar, Bhushan and Burle, Rushikesh and Patil, Pawan and Gaurkhade, Sanskruti and Gundewar, Swapnil and Pacharaney, Utkarsha},
  booktitle={2024 International Conference on Intelligent Systems for Cybersecurity (ISCS)}, 
  title={Machine Learning and Deep Learning Approaches for Automated Diabetic Retinopathy Diagnosis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Since diabetic retinopathy (DR) is the primary cause of blindness in working-age adults worldwide, vision loss must be avoided by receiving early detection and treatment. In recent years, deep learning techniques have become more and more useful tools for automated drug discovery, possibly offering solutions to overcome the limitations of traditional screening methods. In-depth descriptions of the most recent deep learning methods for DR detection are provided in this review article. We begin by discussing the importance of DR screening, its prevalence, and the challenges faced by healthcare systems in managing this condition. Next, we discuss different deep learning architectures used for DR detection, such as CNNs and RNNs, and their combinations. We investigate how to improve the precision, resilience, and interpretability of DR detection models through the use of explainable AI, ensemble methods, transfer learning, and attention mechanisms. We also examine publicly available datasets, evaluation metrics, and preprocessing techniques that are commonly used to benchmark DR detection algorithms. We discuss the limitations and possible uses of deep learning-based deep readout detection, emphasizing the significance of large-scale, diverse datasets, the interpretability of the model, and real-world deployment concerns. The overall objectives of this review are to advance the field of automated DR detection by highlighting recent developments, compiling existing knowledge, and identifying areas that require further research.},
  keywords={Deep learning;Diabetic retinopathy;Reviews;Transfer learning;Imaging;Transforms;Medical services;Diabetic Retinopathy;Deep Learning;Convolutional Neural Networks;Recurrent Neural Networks;Transfer Learning;Ensemble Methods;Attention Mechanisms;Explainable AI;Healthcare;Medical Imaging},
  doi={10.1109/ISCS61804.2024.10581336},
  ISSN={},
  month={May},}@INPROCEEDINGS{9865837,
  author={Sharma, Kavita and Nagappan, Partheeban},
  booktitle={2022 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)}, 
  title={Machine Learning/Deep Learning Algorithms & Variability in Grading Improves Early Detection of DR}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Health condition which mainly influence human retina i.e. cognate by Diabetic Mellitus (DM) is a main thread of Diabetic Retinopathy (DR). As a result of the damage of the retina, it causes vision loss. In accordance with census diabetic individuals who had suffered from diabetics in a long time also have DR issues. As a result, DR has become a critical issue that needs a primary stage screening and assessment in order to prevent vision loss and blindness. Physical diagnosis of the condition is time-consuming and prone to inaccuracy. Furthermore, it is not possible to find an ophthalmologist regardless of location or time. As a result, the need for a highly advanced and computerized intelligent system arises, which can be used to diagnose DR in its early stages. Researchers have proposed a number of Machine Learning (ML) algorithms for the diagnosis of DR for decapods. For determining retinal lesion significantly and for initial stage DR diagnosis various feature extraction and analyzing approaches are recommended. Traditional Machine Learning models, on the other hand, suffer from poor generalization during feature extraction due to limited datasets. Using Deep Learning models, more datasets and high computer processing unit weak generalization problem can be reduced. This study intends to provide a DR overview as well as a brief explanation of previous efforts and current automated methods and improvements, in order to the staring exposure of DR. This paper also discusses the most up-to-date DR lesions as well as the causes and symptoms of DR and focus on how AI/ML approaches helpful in early diagnosis of DR and we have to study more on variability in grading to evaluate the best possible result for screening and improving eye disease mainly caused by diabetics.},
  keywords={Deep learning;Machine learning algorithms;Retinopathy;Computational modeling;Retina;Feature extraction;Approximation algorithms;Machine Learning;Deep Learning;Diabetic Retinopathy;Non-proliferative DR and proliferative DR},
  doi={10.1109/CONECCT55679.2022.9865837},
  ISSN={2766-2101},
  month={July},}@INPROCEEDINGS{11200672,
  author={K, Sudha and R, Priya},
  booktitle={2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)}, 
  title={A Systematic Analysis of Advanced Machine Learning Techniques for Fundus Image-based Diabetic Retinopathy Detection}, 
  year={2025},
  volume={},
  number={},
  pages={961-968},
  abstract={Diabetic retinopathy (DR) is a leading cause of blindness worldwide, necessitating early detection and accurate classification to mitigate these its progression. Fundus imaging has emerged as a noninvasive and reliable method for Diabetic retinopathy (DR) diagnosis. Recent advancements in machine learning (ML) have significantly improved the precision and efficiency of fundus image-based DR detection. This paper provides a systematic analysis of advanced ML techniques employed in Diabetic retinopathy (DR) classification, emphasizing both traditional and deep learning approaches. It explores preprocessing methods, feature extraction techniques, and state-of-the-art classification algorithms, highlighting their effectiveness and limitations. Key challenges such as imbalanced datasets, variability in image quality, and interpretability are discussed, alongside strategies to address issues. The analysis also examines emerging trends, including hybrid models and explainable AI, offering insights into future research directions. This review aims to serve as a comprehensive resource for researchers and practitioners, guiding the development of more robust and accurate ML-based solutions for DR detection.},
  keywords={Deep learning;Diabetic retinopathy;Systematics;Accuracy;Reviews;Industry applications;Imaging;Feature extraction;Market research;Reliability;Diabetic Retinopathy;Fundus Imaging;Machine Learning;Deep Learning;Image Classification;Feature Extraction},
  doi={10.1109/ICIMIA67127.2025.11200672},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10544615,
  author={E, Keerthivasan and Thangavel, Senthil Kumar and Nalluri, Madhusudana Rao and K, Somasundaram and Parthasaradhi, Sathyan and Dhar, Meenakshi Y and Bindu, Avadhani},
  booktitle={2024 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Early Glaucoma Detection through ANSAN-Infused Retinal Vessel Segmentation}, 
  year={2024},
  volume={},
  number={},
  pages={1212-1218},
  abstract={Glaucoma is an optic neurological disease, which is one of leading causes for blindness worldwide. Individuals with glaucoma do not show much of the symptoms for years, and before noticing already will be in an advanced stage of visual field loss. Building glaucoma detection systems with AI that uses fundus images are cheaper options, give us a screening phase for early detection of glaucoma. This paper focuses on comparing various deep learning models (ResNet101, Efficient-Netb3, MobileNetV3, DenseNet201, ResNest50, InceptionV4) for one step detection of glaucoma using fundus images. We have used a custom dataset AKSHI with 1255 glaucomatous and 551 normal images, and a SMDG -19 dataset that combines various benchmarking datasets with 4767 glaucomatous and 7549 normal fundus photographs. Our models demonstrate notable discriminative power, with MobileNetV3 Large achieving a F1-score of 0.87, recall of 0.86, and precision of 0.87, while maintaining an overall accuracy of 0.88 with ROC AUC of 0.94 . On the other segment we have worked on blood vessels segmentation of fundus images using U-net model achieved Jaccard Index of 0.7764.},
  keywords={Glaucoma;Optical losses;Image segmentation;Visualization;Blood vessels;Optical imaging;Retinal vessels;Fundus image;glaucoma;image classification;image segmentation;blood vessel segmentation;U-net;mo-bilenetv3;resnet101},
  doi={10.1109/ICICT60155.2024.10544615},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{11132128,
  author={Siyah, Youssef and El Belghiti, Younes and Minaoui, Khalid and Belmajdoub, Hanae and Saoudi, Samir},
  booktitle={2025 5th International Conference on Emerging Smart Technologies and Applications (eSmarTA)}, 
  title={Enhancing Diabetic Retinopathy Detection: A Deep Learning Approach with Advanced Image Preprocessing}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Diabetic Retinopathy (DR) is one of the main causes of blindness globally, which calls for early intervention in order to avoid permanent vision loss. In this study, a new approach is proposed for DR severity level classification with automatic detection using deep learning and retinal fundus images. An image preprocessing pipeline is introduced to enhance the quality of the images and critical features of the retina. The dataset used for the study was the APTOS 2019 dataset which consists of 3662 high-resolution retinal images divided into 5 levels of severity. For optimal results, the model was prepped with grayscale, contrast adjustments, and contour filling. VGG16, InceptionV3, and MobileNetV2 were the three CNN architectures that were implemented and tested against each other using accuracy, precision, recall, F1 score, and ROC-AUC. Out of all participants, MobileNetV2 was able to exceed the most expectations achieving 99.35% accuracy. Unlike the traditional methods, he was able to capture essential features of the retina, decrease false identified positives, and improve the classification of the stages of DR. The results accentuate the promise of AI-powered diagnostic solutions for fully automated systems for DR screening and sets stage for research involving retinal data as alternative markers for potential cardiovascular disease risks.},
  keywords={Deep learning;Diabetic retinopathy;Accuracy;Pipelines;Gray-scale;Retina;Feature extraction;Filling;Image preprocessing;Convolutional neural networks;Diabetic Retinopathy;Deep Learning;Image Preprocessing;Retinal Fundus Images;Convolutional Neural Networks;Automated Diagnosis;Medical Imaging;Feature Enhancement;Cardiovascular Risk Prediction},
  doi={10.1109/eSmarTA66764.2025.11132128},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10983057,
  author={Dixit, Pooja and Sharma, Shilpa and Vaishnav, Pragya},
  booktitle={2024 IEEE 11th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Deep Learning and Ensemble Techniques with XAI in Diabetic Retinopathy: a Performance-Driven Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Diabetic retinopathy, remains one of the leading causes of blindness globally, particularly affecting industrialized and the developing world. To avoid severe harm, early and correct identification is required. For evaluate this, Deep Learning technique, Ensemble learning, and XAI techniques are used to detect DR with help of retinal image. This paper compares the performances of DenseNet121 and ResNet50 to that of InceptionV3, VGG19, EfficientNetB6 in a ensemble model. To assess the performance of ensemble based algorithms in terms of accuracy, precision, recall and F1-score, instances are created. To improve interpretability and boost clinician trust, XAI is incorporated into the Ensemble Learning (EL) frameworks. The DenseNet121, MobileNetV2, and InceptionResNetV2 hybrid models show outstanding performance during training, achieving a remarkable training accuracy of 98.36 %, along with a commendable precisionrecall ratio. This systematic review seeks to assess AI methodologies specifically utilized for diagnosing diabetic retinopathy in existing studies and future research and applications.},
  keywords={Deep learning;Training;Diabetic retinopathy;Accuracy;Explainable AI;Computational modeling;Retina;Ensemble learning;Residual neural networks;Systematic literature review;Deep Learning;Ensemble Learning;Explainable Artificial Intelligence (XAI);DenseNet121;ResNet50;Hybrid Model},
  doi={10.1109/UPCON62832.2024.10983057},
  ISSN={2687-7767},
  month={Nov},}@INPROCEEDINGS{11059591,
  author={Mowla, Neazmul and Mowla, Md. Najmul and Rabie, Khaled and Alsinglawi, Belal},
  booktitle={2025 International Wireless Communications and Mobile Computing (IWCMC)}, 
  title={A Lightweight Deep Learning Model for Retinopathy of Prematurity Classification in eHealth Applications}, 
  year={2025},
  volume={},
  number={},
  pages={227-232},
  abstract={Retinopathy of Prematurity (ROP) is a vision-threatening condition in premature infants requiring timely and accurate diagnosis to prevent blindness. While electronic health (eHealth) technologies promise to improve neonatal care, automating ROP diagnosis faces challenges such as limited labeled datasets, architectural complexity, and high computational demands. This study introduces LightEyeNet, a lightweight deep-learning architecture optimized for eHealth applications in ROP severity classification. By integrating DenseNet121 and a channel-wise residual attention network block, LightEyeNet enhances diagnostic accuracy and efficiency. Explainable AI techniques, including Grad-CAM and LIME, further improve transparency and clinical interpretability. LightEyeNet achieves 96.28% testing accuracy, outperforming state-of-the-art pre-trained networks, including DenseNet201 (95.78%, + 0.5%), Inception-V3 (93.80%, + 2.48%), Xception (94.54%, + 1.74%), and EfficientDense (87.10%, + 9.18%). Furthermore, LightEyeNet is the most compact architecture among these, with a size of 2.45 MB, compared to Efficient-Dense (6.88 MB), Inception-V3 (3.56 MB), Xception (21.48 MB), and DenseNet201 (5.05 MB). With a specificity of 0.99, a sensitivity of 0.95, and an AUC score of 0.99 across five ROP severity classes, LightEyeNet demonstrates a balance of superior performance and efficiency.},
  keywords={Wireless communication;Pediatrics;Accuracy;Sensitivity;Retinopathy;Neural networks;Computer architecture;Electronic healthcare;Mobile computing;Testing;Retinopathy of Prematurity (ROP);eHealth;Residual Attention Network Block;Convolutional Neural Network;Medical Imaging Classification},
  doi={10.1109/IWCMC65282.2025.11059591},
  ISSN={2376-6506},
  month={May},}@INPROCEEDINGS{10449103,
  author={Sivakamasundari, P. and Niranjana, G.},
  booktitle={2023 Intelligent Computing and Control for Engineering and Business Systems (ICCEBS)}, 
  title={A Critique on Deep Learning Methodologies Employed for the Identification of Diabetic Retinopathy Using Fundus Images}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={In humans, diabetic retinopathy (DR) is a severe problem that can lead to prevent blindness. In many Computer-Aided Diagnosis (CAD) applications, early DR diagnosis is needed to assess the relevance of fundus image features for detection and classification. Based on the intricacy of the lesion characteristics, it becomes challenging to categorize the extent of DR. The test process requires an efficient identification strategy to find the retina's minor problems. Innovative algorithms for deep learning algorithm used for self-identification could potentially stop negative effects like eyesight loss. A very efficient and reliable system may be developed to help doctors autonomously diagnose DR at the beginning, despite the requirement for expert healthcare resources as a result of many advancements in AI methodologies. In order to categorize non-invasive DR, exudates, hemorrhaging, and microaneurysms, several contemporary structures constructed using DL networks are in-depthly examined in this study. This studyoffers a detailed overview of the use of DL algorithms at different phases of automated DR categorization using fundus pictures. On a number of datasets, effectiveness metrics are compared using DL techniques. This study concludes by summarizing the work that has already been completed to improve the accuracy of DL techniques.},
  keywords={Deep learning;Measurement;Diabetic retinopathy;Medical services;Retina;Classification algorithms;Hemorrhaging;Diabetic retinopathy (DR);Computer-Aided Diagnosis (CAD);Early diagnosis;Deep learning algorithms;Automated categorization;Fundus images},
  doi={10.1109/ICCEBS58601.2023.10449103},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10220844,
  author={E, Naseeha Abdulla and Musthafa, Najla and P, Jemsheer Ahmed},
  booktitle={2023 International Conference on Innovations in Engineering and Technology (ICIET)}, 
  title={Precise Localization of Optic Disc Region for Accurate Glaucoma Diagnosis Using Deep Reinforcement Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Glaucoma is a leading cause of blindness worldwide, and early detection is crucial for effective management. In this research will propose a novel methodology for the detection of glaucoma in retinal fundus images using deep reinforcement learning and other modern AI-based algorithms. The proposed method includes This program is built using deep reinforcement learning for active object localization, as well as machine learning techniques. For input picture validation and active object localization for Region of Interest (ROI) detection and feature extracts using CNN, a deep reinforcement learning model with a deep Q network is used on the basis of MDP. The model is tailored to a specific class and allows an agent to focus on areas with the potential to identify the exact location of pressure variation in fundus images happening in the Optic Disc (OD) region called the glaucomatous Region. The agent is instructed to fine-tune a bounding box by means of straightforward transformational actions in order to precisely determine the location of the Optic Disc. The localization agent being discussed is developed using deep reinforcement learning techniques and its performance is measured using the Kaggle fundus images dataset.},
  keywords={Deep learning;Location awareness;Integrated optics;Glaucoma;Technological innovation;Reinforcement learning;Optical fiber networks;Glaucoma;Deep Reinforcement Learning (DRL);Markov Decision Process (MDP);Deep Queue Network (DQN);bounding-box;Retinal Fundus image Dataset;Convolutional Neural Network (CNN);Optic Disc (OD)},
  doi={10.1109/ICIET57285.2023.10220844},
  ISSN={},
  month={July},}@INPROCEEDINGS{10616958,
  author={Akshaya, V and Sashank, S and Subhash, G M},
  booktitle={2024 International Conference on Knowledge Engineering and Communication Systems (ICKECS)}, 
  title={Insight Retina: A Deep Learning Approach to Diagnose Diabetic Retinopathy}, 
  year={2024},
  volume={1},
  number={},
  pages={1-6},
  abstract={The greatest cause of blindness in the world and a frequent cause of diabetes melitus is Diabetic-Retinopathy (DR). To stop vision loss in afflicted people, early identification and decision making are essential. Diabetic - Retinopathy is a eye disorder that is currently being diagnosed manually by ophthalmologists. The diagnosis and recovery takes a great deal of time, effort and money, sometimes even a risk of misdiagnosis. Deep-learning has been the most highly emerging popular method that performs better in many fields, especially in the process analysing data and as well as classifying images from medical imaging. The IdX-DR and EyeArt AI are some existing systems that are legally approved and widely used in many places. Convolution neural networks and transfer learning are widely used as they are more effective. The dataset called Asia Pacific Tele-Ophthalmology Society (APTOS) is a large collection, which contains images acquired using Fundus Imaging and is available in open-source which is used extensively. The Insight Retina uses Contrast Limited Adaptive Histogram Equalization for enhancement of images and pre-trained model Res-Net for detection, thus providing improved performance and a reliable 0.893 Kappa accuracy score from the DR model. Insight Retina then generates a report for the input image providing accurate information about the stage of the Diabetic-Retinopathy.},
  keywords={Adaptation models;Accuracy;Transfer learning;Neural networks;Blindness;Retina;Feature extraction;Diabetic-Retinopathy;deep-learning;IdX-DR;EyeArt AI;APTOS;Transfer Learning;Fundus Imaging;Image Enhancement},
  doi={10.1109/ICKECS61492.2024.10616958},
  ISSN={},
  month={April},}@INPROCEEDINGS{10392102,
  author={Kasar, Mahavir S. and Shedge, D.K.},
  booktitle={2023 7th International Conference On Computing, Communication, Control And Automation (ICCUBEA)}, 
  title={Survey of Cataract Detection and Classification Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Cataracts are a prominent cause of blindness worldwide, yet only a small number of publications have reviewed the current state of AI research and development in this domain. Cataract surgery can be avoided in their early stages if they are detected in time. Computational intelligence is one of the most useful technologies in image processing for addressing difficult challenges. It is unclear which of the many available image classification algorithms is best suited for analyzing and classifying ophthalmic pictures. This overview has the potential to serve as a helpful resource for researchers and medical professionals seeking to enhance cataract identification and grading.},
  keywords={Cataracts;Surveys;Image processing;Digital images;Surgery;Blindness;Retina;Deep learning;CNN;DNN;SVM;PCA;RNN;LOCS-III},
  doi={10.1109/ICCUBEA58933.2023.10392102},
  ISSN={2771-1358},
  month={Aug},}
