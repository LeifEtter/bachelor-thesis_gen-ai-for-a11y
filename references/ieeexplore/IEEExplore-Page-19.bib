@INPROCEEDINGS{11143073,
  author={Rajurkar, Avadhoot and Mirajkar, Owee and Mhetre, Satyam and Mehta, Harsh and Mohol, Siddhi and Gandhe, Mithilesh},
  booktitle={6th International Conference on Recent Trends in Communication & Intelligent Systems (ICRTCIS 2025)}, 
  title={Smart curve guardian: real-time vehicle threat detection}, 
  year={2025},
  volume={2025},
  number={},
  pages={18-25},
  abstract={This study is about the development of a cheap AI powered unit that will monitor the blind spot of the road in real-time with the ESP32-CAM module. It is connected with a streaming camera of live images in which it sends data of frames to a server to identify the vehicles using YOLO (You Only Look Once) and categorize them into divisions of size and type using ResNet-50. The outcome of threat levels is obtained and is utilized to energize the dynamic warning system (of LEDs), which is kept at different speeds of LED blinking depending on the types of vehicles. It is the primary development to optimize data transmissions between resource-limited platform embedded systems and high-performance cloud models, to develop a hybrid intelligent system of transportation applications in remote areas with low infrastructure.},
  keywords={},
  doi={10.1049/icp.2025.2729},
  ISSN={},
  month={June},}@INPROCEEDINGS{11140710,
  author={Sunanda, N. and Adhvy, Vodnala Sharan and Praneetha, Kanvapuri Sai and Sahithi, Katikireddy Sai and Affan, Mohammed Shaji},
  booktitle={2025 8th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Vision to Voice: Transforming Images into Audio Descriptions with Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1973-1980},
  abstract={The visually impaired have great difficulties sensing and engaging with the visual environment. Activities such as exploring public areas, recognizing objects, or retrieving visual information prove to be challenging when not properly supported. Although assistive technologies are available, the majority are short on contextual awareness and natural interaction. In this paper, we introduce "Vision to Voice: Translating Images to Audio Descriptions with Deep Learning", a system that utilizes the BLIP (Bootstrapped Language-Image Pre-training) model to produce precise, context-aware image captions, which are synthesized into speech via text-to-speech (TTS) synthesis. People can upload or photograph to receive real-time audio descriptions, making it easier with a more natural, voice-based interface. Our approach integrates progress in computer vision, natural language understanding, and deep learning to deliver semantically accurate and logically consistent descriptions. It could be applied in mobile apps, voice assistants, and blind-friendly self-navigating devices with offline availability, multilingual support, and AI-powered personalization.},
  keywords={Deep learning;Visualization;Computer vision;Translation;Computational modeling;Personal voice assistants;Real-time systems;Natural language processing;Text to speech;Sensors;Assistive Tech;Visually Impaired;Deep Learning;BLIP;Image Captioning;Audio Description;TTS;Vision-Language Models;Computer Vision;NLP},
  doi={10.1109/ICCMC65190.2025.11140710},
  ISSN={},
  month={July},}@INPROCEEDINGS{10704161,
  author={James, Aashish Joshua and Vangapalli, Neethu Dhwani and Siripurapu, Jahnavi and Chinnamallu, Yashwanth Reddy},
  booktitle={2024 International Conference on Emerging Techniques in Computational Intelligence (ICETCI)}, 
  title={Integration of Voice Assistant with ChatGPT and DALL-E}, 
  year={2024},
  volume={},
  number={},
  pages={95-101},
  abstract={This paper discusses the integration of voice assistant with ChatGPT and Dall-E. JANY is an app that allows users to interact with the app using voice and it gets the subsequent response in speech as well as in text format. In the present-day context, the significance of voice interactions cannot be overstated, as they play a vital role in providing a seamless experience. Our approach involves converting speech to text, where the resulting text acts as an input for ChatGPT and DALL-E, followed by transforming the responses from text to speech. This is done taking into consideration people who can't read or write, the blind, old people, etc. The use of voice assistants integrated with AI like ChatGPT and DALL-E has tremendous potential as it provides an easy user experience and can also be accessed by people who have difficulty using traditional text-based interactions. Further, the paper also discusses the challenges encountered while integrating voice assistants with ChatGPT and DALL-E and how we overcame these challenges. The paper covers the system architecture, API calls, and libraries that were utilized, along with code snippets where required.},
  keywords={Personal voice assistants;Systems architecture;Writing;Chatbots;User experience;Libraries;Text to speech;Artificial intelligence;Speech processing;Speech to text;Voice assistant;ChatGPT;DALL-E;Speech-to-text;Text-to-speech},
  doi={10.1109/ICETCI62771.2024.10704161},
  ISSN={},
  month={Aug},}@ARTICLE{11052629,
  author={Bodi, Anuraag and Bang, Jihoon and Varshney, Neeraj and Berweger, Samuel and Lai, Chiehping and Senic, Jelena and Chuang, Jack and Gentile, Camillo},
  journal={IEEE Antennas and Wireless Propagation Letters}, 
  title={Digital-Twin-Assisted Clustering of Radio-Frequency Multipath Components}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Clustering radio-frequency (RF) multipath components (MPCs) fosters compact channel models by capturing the geometry of the scattering environment, yet “blind” methods based solely on RF data struggle to associate MPCs with individual scatterers. We address this by supplementing the RF channel sounder with camera and lidar systems that, together with AI-based algorithms, generate a segmented digital twin of the environment. By projecting MPCs onto this segmented twin, they are clustered directly according to the segments they fall on. We validate the framework on a robotic arm in a joint communications and sensing (JCAS) scenario, demonstrating reliable clustering by individual robot parts.},
  keywords={Radio frequency;Robots;Digital twins;Laser radar;Cameras;Three-dimensional displays;Image segmentation;Robot kinematics;Robot vision systems;Manipulators;Channel modeling;image segmentation;JCAS},
  doi={10.1109/LAWP.2025.3583481},
  ISSN={1548-5757},
  month={},}@ARTICLE{9978655,
  author={Jivrajani, Krupal and Patel, Shobhit K. and Parmar, Chandrasinh and Surve, Jaymit and Ahmed, Kawsar and Bui, Francis M. and Al-Zahrani, Fahad Ahmed},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={AIoT-Based Smart Stick for Visually Impaired Person}, 
  year={2023},
  volume={72},
  number={},
  pages={1-11},
  abstract={Visually impaired people are facing difficulties during day-to-day activities in terms of traveling and receiving accurate information from their surroundings. Most of the time, visually impaired persons need to rely on others. Blind people cannot walk without the support of a cane. Artificial intelligence of things (AIoT) is the solution to designing smart devices for the visually impaired. We propose a smart stick that overcomes most of the problems of the visually impaired person. The stick actually helps to detect the obstacles faced in day-to-day life. The visually impaired person can also recognize objects and currency with the help of a deep learning algorithm applied to images captured by the camera installed in the stick. The pulse sensor installed on the stick monitors the health of the user. The smart stick is embedded with Raspberry pi and a global positioning system (GPS) that helps in sensing emergency alerts. The proposed smart stick also provides timing information about available buses near the location to enable choosing travel times in advance. Sensors are used for achieving these functions. Android application that is connected with firebase is also developed for tracking data about the user (health, location, etc.) from a remote location. The Overall obstacle detection accuracy of the system is 91.7% for various demonstrations and the single module will be available at around  $\$ $ 50– $\$ $ 60. The proposed system is cost-effective, lightweight and user-friendly. The main goal of this system is to ensure the safety of visually impaired persons and to provide a better life for them.},
  keywords={Acoustics;Global Positioning System;Cameras;Object recognition;Monitoring;Feature extraction;Electronic mail;Artificial intelligence of things (AIoT);deep learning;global positioning system (GPS);global system for mobile communication (GSM);visually impaired},
  doi={10.1109/TIM.2022.3227988},
  ISSN={1557-9662},
  month={},}@ARTICLE{9662980,
  author={Zhu, Fuxing and Zhang, Yundong and Jiang, Weiguo and Qu, Yanchen and Qi, Kaiyue and Guo, Ying},
  journal={Journal of Lightwave Technology}, 
  title={Self-Assembled Highly Sensitive Hybrid Structure Sensor for Vector Curvature and Temperature Measurement}, 
  year={2022},
  volume={40},
  number={8},
  pages={2570-2576},
  abstract={A highly sensitive hybrid structure sensor based on suspended-core fiber (SCF) is proposed for vector curvature and temperature measurement. The sensor is prepared by self-assembly of SCF-based cascaded Fabry-Perot interferometer (cFPI), single-mode fiber (SMF), and fiber Bragg grating (FBG). In view of the asymmetry of the cFPI, theoretical analysis of the beam transmission and spectral characteristics is implemented when the beam is incident from different directions. The two sensing fibers in the triangular distribution sensor will not be located on the neutral plane at the same time, which makes it possible to measure bending in any orientation. The Vernier effect formed by the cFPI enlarges the curvature and temperature sensitivity to −1064.5 pm/m−1 and 50.7 pm/°C, respectively, without affecting the measurement range. The spectrum shows the opposite spectral response when the sensor bending direction difference is 180°. The sensor overcomes the bottleneck of bending sensitive blind spots in dual-fiber sensing. In addition, the sensor maintains a smaller size and more flexible preparation, which is conducive to its application in artificial intelligence, medical detection.},
  keywords={Sensors;Optical fiber sensors;Temperature measurement;Temperature sensors;Sensitivity;Interference;Fiber gratings;Curvature;Fabry-Perot interferometer;fiber Bragg grating;self-assembly;temperature;Vernier effect},
  doi={10.1109/JLT.2021.3138406},
  ISSN={1558-2213},
  month={April},}@INPROCEEDINGS{10226123,
  author={Thantharate, Pratik},
  booktitle={2023 International Conference on Information Technology (ICIT)}, 
  title={IntelligentMonitor: Empowering DevOps Environments with Advanced Monitoring and Observability}, 
  year={2023},
  volume={},
  number={},
  pages={800-805},
  abstract={In the dynamic field of software development, De-vOps has become a critical tool for enhancing collaboration, streamlining processes, and accelerating delivery. However, monitoring and observability within DevOps environments pose significant challenges, often leading to delayed issue detection, inefficient troubleshooting, and compromised service quality. These issues stem from DevOps environments' complex and ever-changing nature, where traditional monitoring tools often fall short, creating blind spots that can conceal performance issues or system failures. This research addresses these challenges by proposing an innovative approach to improve monitoring and observability in DevOps environments. Our solution, Intelligent-Monitor, leverages realtime data collection, intelligent analytics, and automated anomaly detection powered by advanced tech-nologies such as machine learning and artificial intelligence. The experimental results demonstrate that IntelligentMonitor effectively manages data overload, reduces alert fatigue, and improves system visibility, thereby enhancing performance and reliability. For instance, the average CPU usage across all components showed a decrease of 9.10%, indicating improved CPU efficiency. Similarly, memory utilization and network traffic showed an average increase of 7.33% and 0.49%, respectively, suggesting more efficient use of resources. By providing deep insights into system performance and facilitating rapid issue resolution, this research contributes to the DevOps community by offering a comprehensive solution to one of its most pressing challenges. This fosters more efficient, reliable, and resilient software development and delivery processes.},
  keywords={System performance;Memory management;Telecommunication traffic;Pressing;Machine learning;Software;Software reliability;DevOps Monitoring;Intelligent Monitor;Observability in Distributed Systems;Intelligent Analytics;Anomaly Detection;Performance and Reliability Improvements},
  doi={10.1109/ICIT58056.2023.10226123},
  ISSN={2831-3399},
  month={Aug},}@INPROCEEDINGS{10005452,
  author={Gräßler, Iris and Preuß, Daniel and Brandt, Lukas and Mohr, Michael},
  booktitle={2022 IEEE International Symposium on Systems Engineering (ISSE)}, 
  title={Efficient Extraction of Technical Requirements Applying Data Augmentation}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Requirements for complex technical systems are documented in natural language sources. Manually extracting requirements from these documents – e.g., to transfer them to a requirements management tool – is time-consuming and error-prone. Today, machine learning approaches are used to classify natural language requirements and thus enable extraction of these requirements. However, in practice there is often not enough labeled domain-specific data available to train such models. For this reason, this work investigates the performance in artificially generating requirements through data augmentation. First, success criteria for a method for extracting and augmenting requirements are elicited in cooperation with industry experts. Second, the performance in the augmentation of requirements data is investigated. The results show that GPT-J is suitable for generating artificial requirements: weighted average F1-score: 62.74 %. Third, a method is developed to extract requirements from specifications, augment requirements data, and then classify the requirements. As a final step, the method is evaluated with requirements data from three industry case examples of the engineering service provider EDAG Engineering GmbH: assembly latch hood, adjustable stopper hood and trunk curtain roller blind. Evaluation shows that especially the transferability of models is improved when they are trained with augmented data. The developed method facilitates eliciting complete requirements sets. Performance of artificial intelligence models in requirements extraction is improved applying augmented data and therefore the method leads to efficient product development.},
  keywords={Industries;Technical requirements;Latches;Requirements management;Natural languages;Machine learning;Data models;requirements engineering;artificial intelligence;natural language processing;machine learning;data augmentation},
  doi={10.1109/ISSE54508.2022.10005452},
  ISSN={2687-8828},
  month={Oct},}@ARTICLE{10709649,
  author={Zhou, Yirong and Qian, Chen and Li, Jiayu and Wang, Zi and Hu, Yu and Qu, Biao and Zhu, Liuhong and Zhou, Jianjun and Kang, Taishan and Lin, Jianzhong and Hong, Qing and Dong, Jiyang and Guo, Di and Qu, Xiaobo},
  journal={IEEE Transactions on Cloud Computing}, 
  title={CloudBrain-ReconAI: A Cloud Computing Platform for MRI Reconstruction and Radiologists’ Image Quality Evaluation}, 
  year={2024},
  volume={12},
  number={4},
  pages={1359-1371},
  abstract={Efficient collaboration between engineers and radiologists is important for image reconstruction algorithm development and image quality evaluation in magnetic resonance imaging (MRI). Here, we develop CloudBrain-ReconAI, an online cloud computing platform, for algorithm deployment, fast and blind reader study. This platform supports online image reconstruction using state-of-the-art artificial intelligence and compressed sensing algorithms with applications for fast imaging (Cartesian and non-Cartesian sampling) and high-resolution diffusion imaging. Through visiting the website, radiologists can easily score and mark images. Then, automatic statistical analysis will be provided.},
  keywords={Image reconstruction;Magnetic resonance imaging;Cloud computing;Image quality;Deep learning;Reconstruction algorithms;Measurement;Compressed sensing;Statistical analysis;Collaboration;Cloud computing platform;image quality evaluation;reader study;image reconstruction;artificial intelligence;magnetic resonance imaging},
  doi={10.1109/TCC.2024.3476418},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{9914056,
  author={G, Shobana and Reethu and S, Sudheksha and K, Vinothini},
  booktitle={2022 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)}, 
  title={Fruit Freshness Detecting System Using Deep Learning and Raspberry PI}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Food Quality Checking is an essential thing to get rid of food poisoning and diseases, Monitoring the decayable products, and deterioration of fruit at their early stage will decrease the loss of fruit wastage and ensure freshness. Recent technological advancements like Artificial Intelligence and Machine Learning (ML) has important methodologies which may improve the fruit quality cautionary process’s value and time potency. Machine vision techniques are currently wide to discover the quality of fruits. Image process is typically the primary step in detecting the standard of fruits. the method starts by capturing the image of the fruits using camera available. Then, the image is transmitted to the process stage wherever it will extract the fruits options like form, size and color. These processes are done by the image process. It helps to spot and compare the fruit form, size and color with the trained datasets which can be done throughout the prepare and testing stage. This paper aims mainly for blind people where it is difficult for them to check whether the fruit is consumable or not . In this project, a recommendation system is build using various Deep Learning algorithms like Visual Geometry Group (VGG)16 and Convolutional Neural Network(CNN) that is employed for feature Extraction and machine learning algorithms like Logistic Regression, Light Gradient Boosting(LGB) and Random Forest which are used for prediction and a comparative study is made, the performance of each algorithm is calculated which is then integrated with raspberry pi, so that when a customer places the fruit inside a box available, the camera which is present will capture the fruit from all side and will detect whether it is a fresh or rotten fruit and the output is told to the user via voice command/Speaker.},
  keywords={Deep learning;Visualization;Machine learning algorithms;Webcams;Image color analysis;Prediction algorithms;Convolutional neural networks;Fruit quality monitoring;Machine learning;Deep Learning;Algorithm;Internet of Things;Transfer Learning},
  doi={10.1109/ICSES55317.2022.9914056},
  ISSN={},
  month={July},}@INPROCEEDINGS{9887518,
  author={Yang, Fan and Su, Xueping and Ren, Jie and Ma, Xiaomin and Han, Yongyong},
  booktitle={2022 International Conference on Image Processing and Media Computing (ICIPMC)}, 
  title={A Survey of Image Captioning Algorithms Based on Deep Learning}, 
  year={2022},
  volume={},
  number={},
  pages={108-114},
  abstract={As a cross task of natural language processing and computer vision, image captioning is a key technology to explore the transformation of artificial intelligence visual perception to high-level semantic understanding. It is widely used in image retrieval, blind navigation, early childhood education, human-computer interaction, safe assisted driving and other fields. Firstly, the research progress of image captioning is briefly described, and then the image captioning algorithms based on deep learning methods are classified and summarized according to their development history, and the main ideas and core issues of various algorithms are elaborated. Finally, the implementation results of various algorithms are compared, the problems existing in the existing algorithms are summarized and analyzed, and the future development trend of image captioning is prospected.},
  keywords={Deep learning;Navigation;Semantics;Image retrieval;Media;Market research;Natural language processing;image captioning;deep learning;natural language processing;computer vision},
  doi={10.1109/ICIPMC55686.2022.00028},
  ISSN={},
  month={May},}@ARTICLE{10473073,
  author={Matsuhira, Chihaya and Kastner, Marc A. and Komamizu, Takahiro and Hirayama, Takatsugu and Doman, Keisuke and Kawanishi, Yasutomo and Ide, Ichiro},
  journal={IEEE Access}, 
  title={Interpolating the Text-to-Image Correspondence Based on Phonetic and Phonological Similarities for Nonword-to-Image Generation}, 
  year={2024},
  volume={12},
  number={},
  pages={41299-41316},
  abstract={Text-to-Image (T2I) generation is the task of synthesizing images corresponding to a given text input. The recent innovations in artificial intelligence have enhanced the capacity of conventional T2I generation, yielding more and more powerful models day by day. However, their behavior is known to become unstable in the face of text inputs containing nonwords that have no definition within a language. This behavior not only results in situations where image generation does not match human expectations but also hinders these models from being utilized in psycholinguistic applications and simulations. This paper exploits the human nature of associating nonwords with their phonetically and phonologically similar words and uses it to propose a T2I generation framework robust against nonword inputs. The framework comprises a phonetics-aware language model as well as an adjusted T2I generation model. Our evaluations confirm that the proposed nonword-to-image generation synthesizes images that depict visual concepts of phonetically similar words more stably than comparative methods. We also assess how the image generation results match human expectations, showing a better agreement than the phonetics-blind baseline.},
  keywords={Computational modeling;Phonetics;Tokenization;Solid modeling;Image synthesis;Visualization;Task analysis;Linguistics;Psychology;Visualization;Natural language processing;Text-to-image;Nonwords;phonetics;pronunciation;psycholinguistics;text-to-image generation;vision and language},
  doi={10.1109/ACCESS.2024.3378095},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9972564,
  author={M, Nandhagopal S and Saranya, D. and R, Devi Priya and Daniel Shadrach, Finney and Kalshetty, Jagadevi. N.},
  booktitle={2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)}, 
  title={Convolutional Neural Networks for Analysis and Recognition of Facial Expressions}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Facial expression recognition is one of the foundations that gives enormous aid and simplicity for people working in the fields of artificial intelligence, gaming, marketing, and healthcare; it is also one of the foundations that is at the centre of many recent advancements. People are able to communicate their feelings to one another primarily through their facial expressions, which is significant given the significance of emotions as a tool for effective communication. Facial expressions are the primary means through which people convey their sentiments to one another. The process of identifying the feelings that are being sent on a person's face during social encounters is one that is both necessary and challenging. It is feasible to utilise the identification of facial expressions in conjunction with other security measures in order to raise the level of protection that is given to an individual. In the case that a consumer uses an automated teller machine and displays indicators of anxiety, it is possible that the computer will be programmed to refuse to dispense cash to that person. A person who is blind may also benefit from this since it may assist them in understanding the sentiments and facial expressions of the person who is standing in front of them. Discovering others on social media who are experiencing depression via their accounts might also be useful. This may be used in games to assess a player's strong and weak places, and the difference between the two can be formed by analysing the player's expressions at various moments throughout the game. This can be used in games to analyse a player's strengths and weaknesses. The technique known as "feature extraction" was used so that the areas of the faces that were determined to be the most important may be concealed.},
  keywords={Training;Waste materials;Social networking (online);Face recognition;Games;Medical services;Sparks;artificial intelligence;gaming;marketing;and healthcare;facial expression recognition},
  doi={10.1109/MysuruCon55714.2022.9972564},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10602059,
  author={Rosi, A. and Remya Rose, S and Murugan, C.Arul and Balamurugan, E and Priya, M. Sangeetha and Lalitha, K.S.},
  booktitle={2024 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)}, 
  title={Automated Gesture Recognition using Deep Learning Model for Visually Challenged People}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Individuals with visual impairments face challenges in engaging in tasks involving surroundings, social interactions, and technologies. Moreover, individuals are experiencing challenges in being self-reliant and secure in their everyday activities. The blind people may precisely sense and react to emotions with recognition. The current application needs the integration of face and facial expression detection. Technologies seem far more sophisticated than they were in the past. It is possible to identify the communication of a deaf and visually challenged individual by recording their speech and comparing it to existing datasets, therefore determining their intentions. This research presents a system for recognizing hand gestures and faces using animated pictures and techniques. The hand gesture method identifies skin color and hand convex deformities, while the face recognition system utilizes Haar Cascade Classifiers and LBPH recognizer for identification and authentication. OpenCV is used for execution. The study achieved an accuracy rate of $96.3 \%$ in identifying hand gestures and facial features. The system is automated and operates on an artificial intelligence server.},
  keywords={Accuracy;Face recognition;Virtual assistants;Visual impairment;Color;Gesture recognition;Skin;Gesture recognition;Convolutional Neural Network;Hand gestures;Facial features;Haar Cascade classifiers;LBPH recognizer},
  doi={10.1109/ACCAI61061.2024.10602059},
  ISSN={},
  month={May},}@INPROCEEDINGS{11196553,
  author={Khan, Shalfin and Chong, Mien May and Marlia, Zety and Ting, Mary},
  booktitle={2025 International Conference on Metaverse and Current Trends in Computing (ICMCTC)}, 
  title={VI-NETRA: Foreign Currency Recognition for the Visually Impaired in Indonesia Using Image Recognition and Machine Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Indonesia has an estimated 280 million people with disabilities, representing more than 9% of the population, meaning that they are vulnerable to unemployment. The country has documented a 3.0% prevalence of vision loss nationwide. Among the population, there are 8,019,427 individuals with visual impairments, including 1,654,595 individuals classified as blind and 6,364,832 individuals with moderate to severe visual impairments (with a visual acuity of less than 6/18 in the better eye). Less favourable to employment opportunities because of their visual disabilities and limitations, particularly in areas of employment that are necessary to deal with monetary transactions. Consequently, it is necessary to develop a tool to help these people to unlock new employment opportunities in the world of foreign exchange trading. VI-Netra is an innovative mobile application introduced into this research, which aims to use image recognition and artificial intelligence technologies to help visually impaired individuals identify different bank notes in money transactions. To ascertain the effectiveness of the proposed application, interviews were conducted with target audiences, revealing a positive reception among those interviewed. Furthermore, post-development user acceptance testing demonstrated high satisfaction levels among visually impaired individuals who used the application. .},
  keywords={Training;Visualization;Image recognition;Accuracy;Visual impairment;Employment;Machine learning;Mobile applications;Unemployment;Currencies;Currency Recognition;Image Recognition;Machine Learning;Artificial Intelligence;Visual Impaired},
  doi={10.1109/ICMCTC62214.2025.11196553},
  ISSN={},
  month={April},}@INPROCEEDINGS{11059212,
  author={Mehrotra, Tushar and Subramanian, Gokul and Tharan, Ojaswin and Prasad, Rohan Viswanatha and Kyadasu, Rajkumar and Murthy, Kumar Kodyvaur Krishna},
  booktitle={2024 International Conference on Advances in Computing, Communication and Materials (ICACCM)}, 
  title={Deep learning Models Used to Generate the Music in Natural Language Process}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={For the goal of generating art, including music, deep learning-based language models shown encouraging outcomes. However, because to the subjective nature of music, it is difficult to put a numerical value on how well a performance sounds. As a result, most evaluations of symbolic musical generation models rely on simplistic mathematical measures, such the loss function's output. Using just creation of classical piano music, the goal of this study was to quantify and assess musical samples generated by models of deep learning from a human viewpoint. Using musical samples composed by humans and musical samples produced by artificial intelligence models, such as Performance RNN, Music Out of the 118 people who took part in the assessment, 118 were blind tested using Transformer, Muse Net, & a GRU-based proprietary model. During the experiments, it was shown that musical samples created using models based on the architecture of the Transformers neural networks were the most responsive to the test population, surpassing human compositions. In addition, the results demonstrated that participants' ability to identify the compositional source of audible samples was significantly enhanced by their degree of musical sensitivity & competence.},
  keywords={Deep learning;Sensitivity;Neural networks;Music;Transformers;Mathematical models;Loss measurement;Numerical models;Artificial intelligence;Testing;Artificial Intelligence;Music Transformer;Deep Learning;Transformer;Neural Network},
  doi={10.1109/ICACCM61117.2024.11059212},
  ISSN={2642-7354},
  month={Nov},}@INPROCEEDINGS{10831979,
  author={An, Jong-Hyun and Hong, Jung-Ho and Kim, Hee-Dong and Lee, Seong-Whan},
  booktitle={2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={RoPAR: Enhancing Adversarial Robustness with Progressive Image Aggregation and Reordering Noise}, 
  year={2024},
  volume={},
  number={},
  pages={1137-1142},
  abstract={Adversarial attacks mislead deep neural network classifiers with slight perturbations, underscoring the necessity for the development of robust defenses to ensure the secure and responsible use of artificial intelligence. Recent research has shown that diffusion-based adversarial purification methods have emerged as a promising defense technique, but often suffer from computational inefficiencies and suboptimal results. To address these issues, we propose RoPAR, an innovative approach that enhances robustness against adversarial attacks by aggregating purified images at intermediate steps of the diffusion process. Our method improves model robustness while reducing the required diffusion steps. We also introduce a technique for reordering Gaussian noise to minimize semantic information loss while removing adversarial perturbations. These enhancements significantly reduce the number of function evaluations from 200 to 6, achieving a robust accuracy of 92.39 % against preprocessor-blind PGD attacks on CIFAR-10, a 2.29 percentage point improvement over state-of-the-art. Moreover, our method demonstrates its effectiveness in real-world scenarios, achieving 87.46 % accuracy on CIFAR-10C.},
  keywords={Accuracy;Purification;Perturbation methods;Gaussian noise;Semantics;Stochastic processes;Diffusion processes;Sampling methods;Robustness;Artificial intelligence;adversarial defense;diffusion;purification},
  doi={10.1109/SMC54092.2024.10831979},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9984849,
  author={Zhang, Jiajia and Zhan, Mingxin and Qi, Shuhan and Yu, Nanwei and Zheng, Dongrun and Wang, Xuan and Xiao, Jing},
  booktitle={2022 4th International Conference on Data Intelligence and Security (ICDIS)}, 
  title={Information Entropy of Uncertainty Control: An Uncertainty Management Method in Imperfect Information Games}, 
  year={2022},
  volume={},
  number={},
  pages={428-434},
  abstract={With the vigorous development of artificial intelligence, many amazing breakthroughs have been made in recent years, while games often serving as important milestones. After significant progresses in perfect information games' field (e.g, Alpha Zero in Go), studies have gradually shifted to imperfect information games such as Poker, in which uncertainty management is a key part of this. Reconnaissance blind chess (RBC), a variant of chess, provides a good platform for specialized research on uncertainty management problems, because it has an independent “information sensing” stage. In this paper, we propose Information Entropy of Uncertainty Control (IEUC), which is a new method introduce information entropy theory as the optimization target of uncertainty in imperfect information games. IEUC integrates the whole uncertainty of the environment and strategy evaluation to reduce the uncertainty of the environment more reasonably. We realize a practical RBC agent that incorporates IEUC method. In the experiments, our new agent has shown better effectiveness and robustness than several influential opponents in information sensing, including our previous version that won the champion in terms of uncertainty management in NeurIPS 2019 RBC tournament.},
  keywords={Uncertainty;Games;Reconnaissance;Robustness;Sensors;Information entropy;Artificial intelligence;imperfect information game;uncertainty management;Reconnaissance Blind Chess},
  doi={10.1109/ICDIS55630.2022.00071},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10045218,
  author={Sharma, Tushar and Shrivastava, Vivek and Kumawat, Manoj},
  booktitle={2022 IEEE 10th Power India International Conference (PIICON)}, 
  title={A Comprehensive Study on Electricity Theft Detection Using Data Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Electricity theft is the crux of all problems in the power sector. The world has been facing this issue and wants to upgrade the system to overcome this problem. Directly or indirectly, it has been causing enormous financial losses worldwide. In the present scenario, a lot of advancements are made in information technology. Therefore, electrical communication networks can be adopted artificial intelligence methods to increase oversight of each and every blind spot. However, the electrical network system still uses an antiquated manner of theft detection. Nevertheless, private utilities have worked to gather information and examine various elements of electricity consumption. Therefore, the utilities have collected the data in real time. Further, data mining and sample arrangement have been addressed with some neural networking approaches such as fuzzy networking, recurrent neural network (RNN), Fourier Convolution Neural Network FCNN, and time-series recurrent neural network TSRNN. Therefore, this paper has illustrated the shortcomings of the fundamental method and elaborated to advanced and fast algorithms escorted by intelligent decision-making networks to control the electricity theft.},
  keywords={Recurrent neural networks;Data analysis;Convolution;Time series analysis;Decision making;Real-time systems;Data mining;Eelectricity theft;Fourier Convolution Neural Network;Power economics;Revenue loss;Recurrent Neural Network;Time-Series Recurrent Neural Network},
  doi={10.1109/PIICON56320.2022.10045218},
  ISSN={2642-5289},
  month={Nov},}@ARTICLE{11204772,
  author={Ciocarlie, Gabriela},
  journal={IEEE Security & Privacy}, 
  title={The Blind Eye on Artificial Intelligence}, 
  year={2025},
  volume={23},
  number={5},
  pages={4-5},
  abstract={Security and privacy have been an afterthought as technology has evolved throughout the past 50 years. We are seeing the same trend now, but at an accelerated pace for artificial intelligence (AI) technologies. Are we going to adopt AI blindly without considering the right consequences?},
  keywords={Special issues and sections;Artificial intelligence;Computer security;Privacy;Ethics;Taxonomy;NIST;Cyberattack;Cognition;Human factors;Human in the loop},
  doi={10.1109/MSEC.2025.3596734},
  ISSN={1558-4046},
  month={Sep.},}@INPROCEEDINGS{10703389,
  author={Srivastava, Punit and Shrivastav, Priyanshi and Chaturvedi, Nikhil and Yadava, R.L.},
  booktitle={2022 International Conference on Smart Technologies and Systems for Next Generation Computing (ICSTSN)}, 
  title={Retraction Notice: Performance Analysis of AI-based Optical guiding Device for visually compromised person}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  abstract={To defeat the voyaging trouble for an outwardly impeded individual in chiefly outside climate, this paper presents a thought of savvy directing gadget dependent on CNN and fuzzy to distinguish snags like bicycle, vehicle, individual and give an appropriate sound criticism to the client in the wake of working out speed, distance and in the wake of applying fuzzy to exact the result. Work is to diminish the different sensors of distance and speed estimating and perform calculation on pictures to set exact outcomes up to make it financially savvy. It is a difficult situation for blind individual to stroll on themselves in free space or in street of snags. Different techniques have appeared for directing them to move like headlock strategies, multi-sensors combination Algorithm, yet among every one of them because of utilization of sensors its size turns out to be enormous and furthermore get high in cost. To lessen this, we have presented different calculations for exact speed and distance estimations in order to give appropriate sound criticism.},
  keywords={},
  doi={10.1109/ICSTSN53084.2022.10703389},
  ISSN={},
  month={March},}@INPROCEEDINGS{9735035,
  author={},
  booktitle={2022 10th International Winter Conference on Brain-Computer Interface (BCI)}, 
  title={[Conference overview]}, 
  year={2022},
  volume={},
  number={},
  pages={c1-c1},
  abstract={The Tenth International Winter Conference on Brain-Computer Interface (BCI2022) was held from February 21st to February 23rd at the High1 Resort, Gangwon province in South Korea. It featured seven sessions and was the second BCI winter event to be conducted in a hybrid format. BCI2022 was sponsored by Korea University Institute for Artificial Intelligence, Machine Learning group of the Technische Universität Berlin, the Korea Brain Education Society, TC on Brain-Machine Interface Systems of the IEEE Systems, Man, and Cybernetics Society, IEEE Brain Initiative, Korea Brain Education Research Institute. The conference was attended by 160 registered participants from all over the world, which was another big success given the difficult COVID-19 situation. Under a double-blind review process, it accepted 49 submissions from over 10 countries including France, the USA, China, Germany, Israel, Australia, and many more. Overall, 29 papers were accepted for oral presentation, over one third of oral presenters connected from overseas via Zoom, and 20 papers for spotlight presentation, and all accepted papers will be published in the IEEE Conference proceedings.},
  keywords={},
  doi={10.1109/BCI53720.2022.9735035},
  ISSN={2572-7672},
  month={Feb},}@INPROCEEDINGS{10398667,
  author={De Charette, Raoul},
  booktitle={2023 IEEE 19th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={Scene Understanding: Do we even need Labels and Data ?}, 
  year={2023},
  volume={},
  number={},
  pages={xi-xi},
  abstract={Despite their ever growing sizes, computer vision datasets are doomed to reflect only a tiny fraction of our world. The induced biases raise ethical issues and show that blind reliance on data can have critical outcomes when it comes to applications like autonomous driving. In this talk, we will investigate visual scene understanding in the era of large-scale datasets, self-supervised learning and LLMs. Following our recently published research we will question our use of machine learning and data for real and open world scene understanding by navigating through these questions: Are we making the best use of existing datasets ? Can we benefit from more knowledge priors ? Can vision algorithms perform in the unknown open-world?},
  keywords={},
  doi={10.1109/ICCP60212.2023.10398667},
  ISSN={2766-8495},
  month={Oct},}@ARTICLE{10707689,
  author={Yang, Baosen and Tang, Changbing and Liu, Yang and Wen, Guanghui and Chen, Guanrong},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={A Linear Programming-Based Reinforcement Learning Mechanism for Incomplete-Information Games}, 
  year={2024},
  volume={11},
  number={11},
  pages={2340-2342},
  abstract={Dear Editor, Recently, with the development of artificial intelligence, game intelligence decision-making has attracted more and more attention. In particular, incomplete-information games (IIG) have gradually become a new research focus, where players make decisions without sufficient information, such as the opponent's strategies or preferences. In this case, a selfish player can only make reactive decisions based on the changes in environment and state. Thus, blind decisions by players may drift them away from the path of reward maximization, and may even hinder the health of the IIG environment. Therefore, it is necessary to design an effective mechanism to optimize decision-making for IIG players.},
  keywords={},
  doi={10.1109/JAS.2024.124464},
  ISSN={2329-9274},
  month={November},}
